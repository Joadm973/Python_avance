"""
Traitement de CSV et r√©organisation de fichiers journaux.
Point d'entr√©e principal du projet.
"""

import argparse
import sys
from pathlib import Path
from typing import Optional
import re
import pandas as pd

from utils.io import (
    read_csv,
    write_csv,
    read_log_file,
    write_text_file,
    get_all_log_files,
)
from utils.paths import (
    validate_input_path,
    get_output_dir,
)


def parse_log_entry(log_line: str) -> dict[str, str] | None:
    """
    Parse une ligne de journal au format [TIMESTAMP] LEVEL: MESSAGE.
    
    Args:
        log_line: Ligne du journal
    
    Returns:
        Dictionnaire avec 'timestamp', 'level', 'message' ou None si format invalide
    """
    # Pattern: [YYYY-MM-DD HH:MM:SS] LEVEL: MESSAGE
    pattern = r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]\s+(\w+):\s+(.*)'
    match = re.match(pattern, log_line)
    
    if match:
        return {
            'timestamp': match.group(1),
            'level': match.group(2),
            'message': match.group(3),
        }
    return None


def clean_csv_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Nettoie les donn√©es CSV : suppression des doublons, valeurs nulles, etc.
    
    Args:
        df: DataFrame √† nettoyer
    
    Returns:
        DataFrame nettoy√©
    """
    print("  ‚Üí Suppression des lignes vides...")
    df = df.dropna(how='all')
    
    print("  ‚Üí Suppression des doublons...")
    df = df.drop_duplicates()
    
    print("  ‚Üí R√©initialisation de l'index...")
    df = df.reset_index(drop=True)
    
    return df


def organize_logs(logs_dir: Path | str, output_dir: Path) -> None:
    """
    R√©organise les fichiers journaux par niveau (INFO, WARNING, ERROR, DEBUG).
    
    Args:
        logs_dir: R√©pertoire contenant les logs
        output_dir: R√©pertoire de sortie
    """
    logs_path = Path(logs_dir)
    validate_input_path(logs_path, must_exist=True)
    
    # R√©cup√©rer tous les fichiers .log
    log_files = get_all_log_files(logs_path)
    
    if not log_files:
        print(f"‚ö†Ô∏è  Aucun fichier .log trouv√© dans {logs_path}")
        return
    
    # Dictionnaire pour stocker les logs par niveau
    logs_by_level: dict[str, list[str]] = {
        'INFO': [],
        'DEBUG': [],
        'WARNING': [],
        'ERROR': [],
        'OTHER': [],
    }
    
    print(f"üìã Traitement de {len(log_files)} fichier(s) journal...")
    
    # Traiter chaque fichier
    for log_file in log_files:
        print(f"   Lecture : {log_file.name}")
        lines = read_log_file(log_file)
        
        for line in lines:
            parsed = parse_log_entry(line)
            if parsed:
                level = parsed['level']
                if level in logs_by_level:
                    logs_by_level[level].append(line)
                else:
                    logs_by_level['OTHER'].append(line)
            else:
                logs_by_level['OTHER'].append(line)
    
    # √âcrire les logs organis√©s
    print("‚úçÔ∏è  √âcriture des logs organis√©s...")
    logs_output_dir = output_dir / "logs_organized"
    logs_output_dir.mkdir(parents=True, exist_ok=True)
    
    for level, entries in logs_by_level.items():
        if entries:
            output_file = logs_output_dir / f"{level.lower()}.log"
            content = '\n'.join(entries) + '\n'
            write_text_file(content, output_file, append=False)
            print(f"   ‚Üí {level}.log : {len(entries)} entr√©e(s)")


def process_csv(csv_path: Path | str, output_dir: Path) -> None:
    """
    Traite le fichier CSV : nettoyage et export.
    
    Args:
        csv_path: Chemin du fichier CSV
        output_dir: R√©pertoire de sortie
    """
    csv_file = validate_input_path(csv_path, must_exist=True)
    
    print("üìä Traitement du CSV...")
    
    # Lire le CSV
    print(f"   Lecture : {csv_file.name}")
    df = read_csv(csv_file)
    print(f"   Donn√©es initiales : {len(df)} lignes, {len(df.columns)} colonnes")
    
    # Nettoyer
    print("üßπ Nettoyage des donn√©es...")
    df_clean = clean_csv_data(df)
    print(f"   Apr√®s nettoyage : {len(df_clean)} lignes")
    
    # Exporter
    print("üíæ Export des donn√©es...")
    output_file = output_dir / "data_cleaned.csv"
    write_csv(df_clean, output_file, index=False)
    print(f"   ‚Üí Export√© vers : {output_file.name}")
    
    # G√©n√©rer des statistiques
    stats_file = output_dir / "data_stats.txt"
    stats_content = f"""=== Statistiques du traitement ===

Fichier source: {csv_file.name}
Nombre de lignes (brut): {len(df)}
Nombre de lignes (nettoy√©): {len(df_clean)}
Nombre de colonnes: {len(df_clean.columns)}
Colonnes: {', '.join(df_clean.columns)}

R√©sum√© num√©rique:
{df_clean.describe().to_string()}
"""
    write_text_file(stats_content, stats_file)
    print(f"   ‚Üí Statistiques : {stats_file.name}")


def main(
    input_csv: str,
    logs_dir: str,
    output_dir: str,
) -> int:
    """
    Fonction principale.
    
    Args:
        input_csv: Chemin du fichier CSV d'entr√©e
        logs_dir: R√©pertoire des logs
        output_dir: R√©pertoire de sortie
    
    Returns:
        Code de sortie (0 = succ√®s)
    """
    try:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print("=" * 60)
        print("üöÄ D√©marrage du traitement")
        print("=" * 60)
        
        # Traiter le CSV
        process_csv(input_csv, output_path)
        
        print()
        
        # R√©organiser les logs
        organize_logs(logs_dir, output_path)
        
        print()
        print("=" * 60)
        print("‚úÖ Traitement termin√© avec succ√®s !")
        print(f"üìÅ R√©sultats dans : {output_path}")
        print("=" * 60)
        
        return 0
    
    except FileNotFoundError as e:
        print(f"‚ùå Erreur : {e}", file=sys.stderr)
        return 1
    
    except Exception as e:
        print(f"‚ùå Erreur inattendue : {e}", file=sys.stderr)
        return 2


def parse_arguments() -> argparse.Namespace:
    """Parse les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(
        description="Traitement de CSV et r√©organisation de fichiers journaux.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python src/main.py --input data/data.csv --logs raw_logs --out output
  python src/main.py -i data.csv -l logs -o results
        """,
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        required=True,
        help="Chemin du fichier CSV d'entr√©e",
    )
    
    parser.add_argument(
        '--logs', '-l',
        type=str,
        required=True,
        help="R√©pertoire contenant les fichiers journaux",
    )
    
    parser.add_argument(
        '--out', '-o',
        type=str,
        required=True,
        help="R√©pertoire de sortie pour les r√©sultats",
    )
    
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_arguments()
    exit_code = main(
        input_csv=args.input,
        logs_dir=args.logs,
        output_dir=args.out,
    )
    sys.exit(exit_code)
